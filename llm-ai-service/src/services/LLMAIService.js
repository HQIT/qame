// ä½¿ç”¨Node.js 18+å†…ç½®çš„fetch
const fetch = globalThis.fetch;

class LLMAIService {
  constructor() {
    this.defaultConfig = {
      endpoint: process.env.LLM_ENDPOINT || 'https://api.openai.com/v1/chat/completions',
      apiKey: process.env.LLM_API_KEY,
      model: process.env.LLM_MODEL || 'ecnu-plus',
      maxTokens: parseInt(process.env.LLM_MAX_TOKENS) || 100,
      temperature: parseFloat(process.env.LLM_TEMPERATURE) || 0.7,
      timeout: parseInt(process.env.LLM_TIMEOUT) || 10000,
      systemPrompt: process.env.LLM_SYSTEM_PROMPT || 'ä½ æ˜¯ä¸€ä¸ªèªæ˜çš„æ¸¸æˆAIåŠ©æ‰‹ã€‚è¯·åˆ†ææ¸¸æˆçŠ¶æ€å¹¶é€‰æ‹©æœ€ä½³ç§»åŠ¨ã€‚'
    };

    console.log('ğŸ§  [LLM AI Service] åˆå§‹åŒ–å®Œæˆ');
    console.log('ğŸ“ [LLM AI Service] é»˜è®¤é…ç½®:', {
      endpoint: this.defaultConfig.endpoint,
      model: this.defaultConfig.model,
      hasApiKey: !!this.defaultConfig.apiKey,
      maxTokens: this.defaultConfig.maxTokens,
      temperature: this.defaultConfig.temperature
    });
  }

  /**
   * è°ƒç”¨LLMè·å–AIç§»åŠ¨
   * @param {string} prompt - æ¸¸æˆçŠ¶æ€æè¿°
   * @param {object} customConfig - è‡ªå®šä¹‰LLMé…ç½®
   * @returns {Promise<number>} ç§»åŠ¨ä½ç½®ï¼Œ-1è¡¨ç¤ºå¤±è´¥
   */
  async getAIMove(prompt, customConfig = {}) {
    const config = { ...this.defaultConfig, ...customConfig };

    if (!config.apiKey) {
      console.error('âŒ [LLM AI Service] ç¼ºå°‘APIå¯†é’¥');
      return -1;
    }

        try {
      console.log('ğŸ§  [LLM AI Service] è°ƒç”¨LLM API...');
      console.log('ğŸ“¤ [LLM AI Service] è¯·æ±‚é…ç½®:', {
        endpoint: config.endpoint,
        model: config.model,
        hasApiKey: !!config.apiKey,
        timeout: config.timeout
      });

      const requestBody = {
        model: config.model,
        messages: [
          {
            role: 'system',
            content: config.systemPrompt
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: config.maxTokens,
        temperature: config.temperature
      };

      console.log('ğŸ“¤ [LLM AI Service] è¯·æ±‚é…ç½®:', {
        endpoint: config.endpoint,
        model: config.model,
        hasApiKey: !!config.apiKey,
        timeout: config.timeout || 'default'
      });
      console.log('ğŸ“¤ [LLM AI Service] è¯·æ±‚ä½“:', JSON.stringify(requestBody, null, 2));

      const response = await fetch(config.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.apiKey}`,
        },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        console.error('âŒ [LLM AI Service] LLM APIè¯·æ±‚å¤±è´¥:', response.status, await response.text());
        return -1;
      }

      const data = await response.json();
      const content = data.choices?.[0]?.message?.content?.trim();

      console.log('ğŸ§  [LLM AI Service] LLMå“åº”:', { content });

      // å°è¯•ä»å“åº”ä¸­æå–æ•°å­—
      const move = this.extractMoveFromResponse(content);
      
      return move;

    } catch (error) {
      console.error('âŒ [LLM AI Service] LLMè°ƒç”¨å¤±è´¥:', error.message);
      return -1;
    }
  }

  /**
   * ä»LLMå“åº”ä¸­æå–ç§»åŠ¨
   * @param {string} content - LLMå“åº”å†…å®¹
   * @returns {number} ç§»åŠ¨ä½ç½®ï¼Œ-1è¡¨ç¤ºæå–å¤±è´¥
   */
  extractMoveFromResponse(content) {
    if (!content) return -1;

    // å°è¯•å¤šç§æ–¹å¼æå–æ•°å­—
    
    // æ–¹å¼1: ç›´æ¥è§£æä¸ºæ•°å­—
    const directNumber = parseInt(content);
    if (!isNaN(directNumber)) {
      return directNumber;
    }

    // æ–¹å¼2: æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ•°å­—
    const numberMatch = content.match(/\d+/);
    if (numberMatch) {
      return parseInt(numberMatch[0]);
    }

    // æ–¹å¼3: æŸ¥æ‰¾ä½ç½®æè¿°
    const positionKeywords = {
      'å·¦ä¸Š': 0, 'ä¸Šä¸­': 1, 'å³ä¸Š': 2,
      'å·¦ä¸­': 3, 'ä¸­å¿ƒ': 4, 'å³ä¸­': 5,
      'å·¦ä¸‹': 6, 'ä¸‹ä¸­': 7, 'å³ä¸‹': 8,
      'top-left': 0, 'top-center': 1, 'top-right': 2,
      'middle-left': 3, 'center': 4, 'middle-right': 5,
      'bottom-left': 6, 'bottom-center': 7, 'bottom-right': 8
    };

    for (const [keyword, position] of Object.entries(positionKeywords)) {
      if (content.toLowerCase().includes(keyword.toLowerCase())) {
        return position;
      }
    }

    console.warn('âš ï¸ [LLM AI Service] æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆç§»åŠ¨:', content);
    return -1;
  }

  /**
   * éªŒè¯ç§»åŠ¨æ˜¯å¦æœ‰æ•ˆ
   * @param {number} move - ç§»åŠ¨ä½ç½®
   * @param {array} validMoves - æœ‰æ•ˆç§»åŠ¨åˆ—è¡¨
   * @returns {boolean} æ˜¯å¦æœ‰æ•ˆ
   */
  isValidMove(move, validMoves) {
    return validMoves.includes(move);
  }
}

module.exports = LLMAIService;
